all right tell me if this sounds familiar you've got a list of company names maybe from a trade show a business directory or something you pulled from Google but that is all you have no emails no phone numbers no real ID of who the real decision makers are so now what you either waste hours manually searching for context or you just guess and hope for the best but what if I told you there's a way to automate this entire process like plug in a company name and within minutes you get everything company details LinkedIn

profiles decision makers and most importantly verified emails to actually reach them sounds too good well let me show you exactly how it works if you are new here my name is Clarence and I run a lead generation agency where I build fully automated outbound systems and let me tell you this happens to me all the time a client comes to me with a lead list companies they think are a perfect fit but the problem is they have nothing they have no emails no phone numbers no clue who the decision makers are to

reach out to just a spreadsheet full of company names manually finding all that info is painful it is slow and let's be real by the time you are done half those leads might not even be relevant anymore so what I did is I built a system that does everything for you the system you see on screen is the one I'll be showcasing today and here's how it works first it cleans the company name so we can search them properly then it finds the company's website their LinkedIn and any key details after that it scrapes sales navigator to pull

a list of all employees using AI it identifies those decision makers from that entire list of employees so you don't waste time on the wrong people and finally it fetches and verifies their emails so you have direct contact info ready to go no more guessing no more wasted hours just a fully automated system that gives you everything you need for outreach in minutes and here is the best part if you want to download this exact workflow and start using it yourself you can do so by joining my school Community inside my school

Community you can download all of the workflows that I showcase on my YouTube channel just click the link in the description to get access not only do I share all my automation workflows I also share all the EXA processes I've used to scale my business this will save you so much time compared to building it from scratch but all right now that you've seen the full picture let's break it down into steps so you can see exactly how it works and you could even replicate it if you want to as a trigger

we're using a manual trigger that starts the workflow it runs whenever you click the test ensuring that the automation kicks off from the beginning now ideally and usually this would be a web hook so the process runs fully automatically without me needing to start it manually but since this is a showcase and for today's demo I've swapped it out to do a manual trigger so I can show you exactly how everything works in real time moving on to the air table note this is where we pull in a single record from our CRM

air table holds all or lead data so in this case it's just a large list of company names but for this workflow we're only grabbing one record at a time to process the key thing to note at the start of this workflow is that all we have is the company name you can see it on the right side the output side so all we have is out for theer which is touch but in this case this is the company name we're after so it's snow start software and for some reason their location is part of their name which actually does make it easier for us to

do a refer search and find the exet company instead of a best estimated guess so the company names or let me say the lead lists aren't always perfectly formatted so it might have extra words it might have typos or inconsistencies that could throw off or search so what we do is we use a large language model note this is used to standardize and clean the name ensuring we get accurate results when searching in Apollo it also encodes the name so it can be used in a URL based query without breaking the

search without this step we'd risk bullying the wrong company or getting unreliable data so this step makes sure we're working with a clean scannable name that we can also use to do the refer search in the the next step now that we have a clean company name we can search for it in apollo.io Apollo for those who don't know is one of the largest B2B databases for company and contact details so this is where you start filling the missing data things like the company name their company's LinkedIn profile and other key details

that we'll need later the scraper we're using is called the abolo company search scraper this tool automates the entire lcer process extracting structured company data directly from Apollo so we don't have to manually search for each company instead scrolling through results we get everything we need instantly now let's take a look inside this note this is where we Define the search query and you can see in the Json body how we're manipulating the URL to perform a refer search instead of searching by domain or industry we're

injecting the clean name directly into the query you can see it here highlighted in green this ensures we're getting the the most exact match possible instead of wasting time filtering through irrelevant results with this we now have the Core Company data we need to move on to the next and you can see it on the right side that it found a company which matched the search quy Snell which is also the name of the company and we have all the details as you can see phone number website uh company LinkedIn the keywords that they

use amount of employees they have and even their exact location however since we're doing a keyword search Apollo doesn't always return a single result sometimes it outputs a list we get multiple companies with similar names so this code note we use merges all of the results from the scraper so we can process them as one data set instead of individual items so now that we've merged all the results from the Apollo scraper with the code note we need to find the best match because not every search returns a single perfect result

and this is where the AI step comes in instead of manually filtering through company names we pass the scrape results into a llm powered selection process the AI compares the company name and location from our original lead against the scrape data and selects the closest match now let's have a look at the prompt driving the process the AI follows a strict set of rules to ensure we always get one best match no more no less first it checks company name similarity prioritizing exact or near matches then if the location isn't an

exact match it uses topographic knowledge to pick the geographically closest company within the same country The Prompt also prevents irrelevant outputs if there's no exact company match the AI finds the most logical Choice based on both name and location combined the final output as you can see is always structured in Json containing just the essential details company name website LinkedIn URL and Geographic info so we can plug it straight into the next step also important to note that we extract the LinkedIn uid which is like

the organization's code for LinkedIn we need this to do a scrape of sales Navigator since in this step we're passing both the lead info and scrape data dynamically the llm adapts in real time this insures were always pulling the most relevant company details before moving forward now that we have found the best company match the next step is scraping their LinkedIn page the goal here isn't to gather company details but to retrieve the exact company name as it appears on their own LinkedIn since

sales Navigator searches require an exact match this ensures we're using the correct name format for the next step but of course the HTML you can see on the right side is way too much we need to filter it down need to get rid of all of the code so what this code node does is that it takes all of the HTML which we got from scraping the company LinkedIn page and you can see it on the left side as input and it filters out all of the code it only returns us the text in this case the plain text and you

can see that on the output side this ensures that when we move forward we're only working with relevant information free from clutter and it also saves us a bunch of input tokens were if we were to input this into an llm so now that we've cleaned the HTML from the LinkedIn page and all we have left is the text the next step is to identify the exact company name using AI this once again ensures we're working with the official LinkedIn registered name avoiding inconsistencies that could mess up or

sales Navigator search by standardizing the name we make sure all future searches and email lookups are based on the correct format preventing mismatches or any irrelevant results now that we have the verified company name and the LinkedIn uid not to forget we can pull all the employees from LinkedIn sales Navigator this step is very crucial because it gives us a pull of potential decision makers the people we actually want to contact as you can see the scrape returned us 203 items meaning 23 employees are registered for

this company on LinkedIn this is the full list of employees at this company you can see that for each person we're capturing key details like their name their job title their location even their LinkedIn profile URL and a lot more now if we jump over to sales Navigator you'll see that this matches exactly what we'd find if we searched manually so let me quickly go to sales Navigator you can see at the top that for this company Snell start which is the company where we did the search qu for there are 203 employees on LinkedIn

which is the exact number that we just scraped the difference between doing this manually and automating is that instead of clicking through pages and copying details one by one this workflow automates the entire process collecting in this case hundreds of profiles in seconds with all these employees now structured as data the next step is filtering out the decision makers because we don't need to contact every employee just the ones who actually make things happen before we can use this input for any llm we first have to use a

code note the code note does the following it merges all of the 2 three separate items into a single structured format right now the data exists as individual output separate employee records from LinkedIn merging all of these individual items into one is essential for the llm to go through the entire list and actually be able to pinpoint the decision makers that we need so with the entire list merged into one we need to now filter out the noise and focus on the people who actually have authority so what this AI does is

it scans through job titles identifies leadership roles and Returns the top five most relevant decision makers the model prioritizes seos sfos VPS directors and heads of Department ensuring we don't waste time on relevant contacts it also recognizes job titles in multiple languages so if you're using this for companies abroad where there might be different it doesn't matter if a company is using director orente the AI and understands if there are more than five relevant contacts it ranks them by importance making sure we always

get the most influential people first instead of just pulling random names and trying to find their email addresses this step uh transforms raw employee data into a targeted contact list that we can actually use the output is once again structured in a Json format ready to be fed into the next step the next step is actually turning this Json into a string because we'll be ning it later on in the workflow for another llm we're not doing anything crazy we're just making sure that the data is formatted

correctly so we can use it as input later on with the final llm node now that we have our list of top decision makers the next step is finding their verified email addresses to do this we send a book request to the any email finder API providing the first last and domain name of each cont any meil finder for those who don't know scans its database and runs validation checks to return only verified emails ensuring we don't waste time with outdated or incorrect email addresses so once this HTTP note has been triggered

the request has been sent but the data isn't ready yet so I use a manual weight note it's just the easiest especially for finding five email addresses it is done within a minute so with that knowledge I can just set the this wait note to a minute then once the minute is over we send a second API request to retrieve the completed results it is a CSV file so it looks a bit messy but if any mfinder was able to verify any emails this is where we get them at this stage we should now have fully verified

ready to use email addresses for our decision makers ensuring that when we reach out we're actually getting into their inbox so unfortunately not all email addresses returned by any mail finder will be verified for some leads it won't even be able to find an email address so what we have to do is filter out the noise once again using this llm node so what this prompt is meant to do is it ensures we only keep leads with a verified email removing any that are either unverified or incomplete the AI

follows a strict set of rules to clean up the data the verification status is determined solely from the Cs fee so what was returned from any mail finder any verification mentions in LinkedIn reference data are ignored emails that are found but not verified are also excluded and then each verified lead is mapped correctly with their LinkedIn URL their job title and the company domain which was the output from the stringified code note this ensures a very clean and structured output as you can see on the right side of this note

which is the final list of only fully verified usable contacts formatted in Json so the workflow can continue without any errors if no verified leads are found the output returns an empty array this step ensures that when we move forward we're only reaching out to highquality verified contacts no wasted efforts on bed data and no bounced emails so before we can upload this lead list we have to split it out at this stage the llm has returned a single object with a list of all the verified leads but to upload them back into air

table our CRM we need to split them into individual records so we use a very simple split out note this step just breaks the batch output into separate entries ensuring that each decision maker is processed as an individual record without this the entire data set would be treated as one large entry making it impossible to store or use effectively once split each verified lead is now ready to to be uploaded into our CRM fully structured and ready for outreach so the final step is storing them in air table each decision maker

with a verified email is now added as a structured record containing all the enrich details we've gathered so their first name last name verified email address LinkedIn profile job title and Company domain as you can see in the air table output this gives us a fully enriched lead profile ready for the next stage scraping more personalized data and setting up automated Outreach instead of wasting time searching manually we now have everything we need in one place fully verified and structured for Action at this point the

workflow is complete and we're left with high quality Outreach ready leads all generated automatically and that is the full breakdown of this workflow starting from just a company name we've automated everything finding decision maker verifying emails and structuring the data for outreach this entire process would normally take at least 30 minutes for just a single company now imagine doing this at scale thousands at a time but with AI and automation it basically runs on autopilot once again if you want

to download this exact workflow and start using it yourself it is available inside my school Community that's where I share all my automation workflows my systems and the exact strategies I've used to skill my own business click the first link in the description to get access if you've made it this far first off huge thanks for watching if you found this valuable make sure to like the video subscribe for more automation tutorials and drop a comment if you have any questions or ideas for future videos

that is going to be it for today I will see you in the next one

