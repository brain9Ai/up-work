there are two types of people in outbound sales the ones who blindly scrape leads and send C emails to whoever they can find and the ones who use data Automation and filtering to make sure every email they sent goes out to the right person the difference the first group wastes time the second group books calls I built a system that does exactly that an automated workflow that finds SAS leads qualifies them and make sure they actually fit my IP before I ever reach out if you are new here I am Clarence I run a lead generation agency

that helps businesses land more sales using Ai and automation my focus isn't just on getting leads it is on getting the right leads efficiently with as little manual work as possible this exx system you see on screen is how I landed seven clients in a single month no manual lead scraping no guesswork just a fully automated workflow that brings in high intent prospects every day I've spent months refining this process and today I'm going to show you exactly how I automate SAS Le generation and qualification so I never waste time on

any bad prospects now if you want to skip this setup and get this entire workflow instantly you can grab it inside my school Community inside you'll get access to this automation my business Sops and support for me along with a group of people all working on scaling their own AI powered lead gen agencies if you're serious about building a system that consistently brings in high quality leads check it out the link is in the description but all right for now promo over let me show you this entire system first we'll break

down the Apollo scraping workflow so you can see exactly how we're pulling these SAS leads let's get into it so first up we use Apollo to clean a list of SAS leads I'm running this through apify which ully scrapes lead data based on my criteria once it is triggered the workflow sends a request to the Apollo scraper which goes out and find companies that match my filters that data gets stored in a data set which will retrieve later on in the same flow let me quickly show you how I set up these filters in Apollo to make sure

we're only getting high quality leads as you can see looking at the filters I'm only pulling leads with verified emails so every contact is actually reachable next I'm targeting decision makers so SE Suite Executives owners and Founders since they're the ones who actually make purchasing decisions I've filtered for SAS companies by using a keyword filter SAS companies with 5 to 30 employees big enough to need outbound but small enough that I don't have an internal Sal team handling it already for this campaign

I'm focusing on the US market but you can adjust this based on your target audience as I already said finally I'm filtering it for SAS companies filtering by an industry keyword to make sure we're only pulling in related leads once Apollo finds these leads you can see it has found 16.4 th000 leads the workflow takes over and starts processing the data now here is the challenge the Apollos scraper doesn't return data instantly you could set the workflow or you can set the endpoint URL to wait for

the data set to be ready but there's a hard time limit for 4 minutes and scraping a list of 16.4 th000 people as I just showed you will easily take way more than 30 minutes which means the workflow would fill so instead of waiting we use a workaround so first we trigger the scraper then in instead of stopping the workflow we merge and verify whether the data set is ready if the data isn't ready yet the workflow pauses and checks again later once it is available we pull in the leads and continue processing them this way the

workflow doesn't break I'm not going in too much detail because this workflow as you see it on screen has already been showcased in previous videos so if you want a full detailed setup you can just go look for the Apollo scraper video on my channel but to save everyone some time who's seen it already I'll just jump Straight Ahead once the data set is available we make sure we're not adding duplicate leads using this remove duplicates note this step removes any duplicate emails or companies before

pushing them to my CRM and for my CRM we use air Table after that all the clean filtered leads get added straight to air table I'll quickly show you my air table so you guys have an idea of what that would look like so I did a very small scrape of only a handful of companies as you can see with have their first last names their email addresses and their title and their company name enough for us to get started with the qualification and the enrichment so that is the lead generation part of the system scraping

filtering and cleaning lead lists before we ever do some enrichment or sending out an email next we'll take these leads and en Rich them with LinkedIn data check their pricing pages and filter out bad fit SAS companies that is where the real magic happens so let's dive into that next before ever building a qualification and enrichment flow like what you see on screen now you need to start with your email template so with writing your email copy you might be wondering why well this is because the

way you structure your email determines what kind of data you need to scrape what kind of data sources you need to scrape for example if you're writing a hyper personalized first line you need company insights or maybe some reason news if you're referencing a company's pricing you need to scrape their pricing page without knowing this up front you end up wasting time pulling data you don't actually need so before we jump into the second part of this workflow let's take a quick look at my email template inside instantly so my email

template is always structured the same or at least in a very similar way so I always start off with a personalized Line This personalized line is written by AI we'll get to that later on in this workflow then what I do is I come with my offer kind of the attention grabber so in this case I say we help company overviews companies like them like the lead were researching now or enriching land meetings with their ICP dealing with the paino that they can actually solve using AI driven Outreach so that

is kind of My Method AI driven Outreach that delivers decision makers not just replies then I have some social proof for another primary Services SAS we book 37 calls in a month 12 converted yada yada we after the social proof we add a guarantee adding a guarantee just kind of reinforces your offer makes you look like an authority figure and makes you come across very confident about your own abilities after the guarantee it is followed up by a CTA a call to action in this case I'm just asking if it's worth

a quick chat yes or no you could also be asking if it's okay to send over more information kind of like more of a passive call to action also works very well sometimes or you could ask to send over a personalized video if you have the time and to know how to make a quick personalized video it does greatly improve your conversion rate all right now that we know what kind of data we need let's break down the workflow that automates all of it so let me quickly take you back to the workflow as you can

see all the way on the left the workflow starts when I manually check a checkbox in my air table checking that checkbox triggers a web hook which sends the record ID of the specific lead into the workflow this setup ensures I have complete control over when a lead get enriched instead of automatically processing every new lead once the web hook fires the workflow retrieves the full lead details from Air table using the record ID this includes the company name their website their LinkedIn URL and any other data already collected

this step ensures we working with a structured data set before running any enrichment before moving forward we do a very quick check to verify if the companies based in us or not since this campaign only targets us-based SAS companies if the company is not in the US it gets marked as not qualified in air table and the workflow stops processing it if the company is in the US it moves on to the next step which is scraping their organizations LinkedIn at this stage the workflow sends an ATP request to scrape all the raw HDML from

the company's LinkedIn page this includes everything visible on the page from the company description to their exact employee count industry tags and other metadata as you can see the data is pulled in as raw HTML meaning the next step will need to clean it up before we can analyze it properly once the LinkedIn page is scraped we remove any unnecessary HTML from the extracted text this makes it easier for AI to analyze and classify the company properly as you can see on the left side that's exactly the same stuff but on the

left side you can see all of the HTML still present and on the right side you can see only plain text is returned the cleaned LinkedIn data is sent to a large language model which is tasked analyzing the company and determining whether it's a good fit for outreach AI outputs a structured response with the following Fields if is B fitas is yes the workflow marks a lead as not qualified and updates air table accordingly if is B fit size is no and the company is clearly B2B focused it moves forward for

further qualification the number of employees field is also extracted to help refine targeting based on the company size because sometimes lead databases like Apollo or LinkedIn sales Navigator can be outdated meaning the company size isn't accurately present in that database we then use a bunch of if noes to determine if the company is not a good fit if it is not a good fit it is immediately updated in my air table and the status is changed to not qualified meaning also the workflow stops processing it at this stage we filtered

and enriched the lead with LinkedIn data now we shift to analyzing the company's website to extract valuable URLs like pricing Pages funding pages and you could also use case studies for example so the HTTP request Noe which I've called the header links scraper scrapes all of the HTML from the company homepage in this case it is www.hot glue.com so we scrape their entire homepage this includes all of the navigation links but it also includes all of the text present on that homepage which we could use later on if you want

to use the enrich data from the homepage to fill in some variables for your email template as I said inside of this HTML are also all navigation links which are present on the homepage so also all links to in this case pricing Pages for example what we do to extract those URLs is we use a code note which filters the HTML and only outputs us any links as you can see- unified accounting - unified e-commerce and there's a lot of pages but somewhere is also probably a road map case studies you can see above

probably some pricing somewhere as well so after removing the raw HTML clutter this step isolates actual internal website links that may contain useful information the goal here is to get a list of all pages that belong to the company's domain and have potential lead qualification value at this point we may have dozens or even hundreds of internal links in this case we have 206 links they are all outputed individually so what we need to do is turn them into a single item to do so we use another code

note this code note turns all of the separate items into a stringified text which makes it much easier for the llm which comes after this to go through the list and determine any valuable URLs so as I said the AI model that comes after now analyze es all extracted links and classifies them based on their relevance it looks for specific patterns that indicate important Pages such as pricing Pages you could tell it to look for funding Pages case studies testimonials or product pages and solution Pages once

identified only the most valuable URLs for your specific use case are passed forward for further scraping well in this case I only told it to look for pricing pages so the only output that it gave us was the URL or the navigation link to the pricing page of hotg glue.com of which we scrap the homepage however if no pricing Pages would have been found the workflow simply skips the pricing analysis and moves forward with the remaining enrichment steps meaning that even if pricing isn't available but

the lead still P all other qualification metrics the chances are pretty big that they are interested for us to reach out to so it still goes through the rest of the enrichment process where the variables for the email template are determined the company name is cleaned as I always do and a personalized line is written then it is all updated to my CRM and it's automatically uploaded instantly which is the email service provider I use for automated Outreach but now let's move on to the branch of this flow for in case the pricing Pages

were available and were determined by the L so now that we have identified a potential pricing page the next step is to extract the actual content and analyze whether the company is low ticket or high ticket size since companies may have multiple relevant Pages for example different pricing tiers or Regional Pages the split out note ensures that each pricing page is processed individually in this case there's only one page so you can see that one item remains one item even after the split out note then each

pricing page is sent to a HTTP request note which extracts the raw HTML from the page once again this pulls all visible text including plan names and descriptions pricing models if they're on the page maybe even some information if they have free trials or freemium mentions if multiple Pages were processed the aggregate note is supposed to merge all extracted data into one single structured response this ensures that the AI has access to the full pricing structure before making a decision of course since there was still

a lot of HTML present in the scrape we need to use another code note to filter out that HTML once again on the left side you can see a very messy item and on the right side you can see all of the HTML filtered out and only the plane text returned now that the pricing data is clean the AI determines pricing by analyzing the following whether pricing is publicly available or requires a demo call if the company offers a free plan or freemium model whether it qualifies as low ticket meaning less than $50 per

month or high ticket and it is supposed to once again output it as a Json so it is easier for us to use it in future notes if the AI detects premium free plan or low ticket pricing the lead is flaged as low ticket and the workflow updates the lead in air table as unqualified if the pricing suggest Enterprise sales custom quotes or high ticket te the lead continues for final enrichment because that is interesting for us to reach out to now that we have filtered out low ticket SAS companies let's move on to extracting additional

company details for final Outreach personalization the next step is kind of the same as it was for the companies who didn't have any pricing on the website the company analysis is done based on LinkedIn data this ensures that every lead has a comprehensive profile before being sent for outreach the analyze company LinkedIn node processes all extracted LinkedIn data and structures it into a detailed company profile as you can see on the right side The Next Step expands on the previous LinkedIn scraping by extracting the company size

and check employee account industry classifications announcement and growth marketing positions and differentiators for example so no matter situation we always have enough to qualify the company and highly personalize Outreach since the AI processes LinkedIn data into structured Json the Json into text note converts it into a format suitable for analysis and personalization so all it does it takes the individual Json and puts it into one large item of text at this point the workflow checks whether

the company has funding information available if funding data is present meaning if the organization's LinkedIn scrape returned us any information from a funding round in this case it did as you can see here looking at funding information so on November 11th 2024 hot glue which is the company we scraped the information from raised $4 million in a seed funding round very interesting for us to write a high personalized line about not only is it quite recent November 11th but it's also quite a Hu huge milestone for the company so it's a

good topic to pick as a personalized email opener if no funding data would have been available the workflow moves forward using an alternative personalization Source such as company growth Trends recent announcements or industry specific insights in this case I chose that if funding information about the company wasn't available the workflow default to a high converting generic sentence that still feels natural and engaging the determine variables node processes the LinkedIn analysis from the previous llm and

funding data to extract the most relevant insights for outreach meaning it gives us the answers to the variables we need to inject into our email template this ensures that every C email includes a compelling company specific detail making the Outreach feel highly personalized next up cleaning the company name I already touched upon it a bit before inserting the company name into the email this step removes unnecessary suffixes such as LLC Inc limited core you name it this is done because company suffixes aren't natural

in conversation and would make the email opener or the email in general no matter where you place it feel robotic bringing us on to the last large language model note which is tasked to write or generate a highly personalized first line opener based on the strong insights in this case if funding data is available it highlights any recent investment or investor backing so I'll quickly read you the outputed line congrats on raising $4 million in your seat round with 8 VC white combinator correlation Ventures and wayfinder

Ventures exciting times for hot glue how are you planning to accelerate development efforts with this new funding so it not only writes a personalization about how much money they raised and the investors that are backing them now it also immediately transitions kind of into the next part of the email which is my offer by turning this over into saying exciting times for hot glue how are you planning to grow as a company which is kind of the perfect opener for me to introduce my offer of helping them

get more leads and grow their business essentially as I said if funding information would not have been available ailable this would have sent this down a different route and a pretty generic personalized line would have been filled in by the AI you could also choose to go for a different data source with different variables which are always present on either the company website or the company LinkedIn because we've scraped both data sources but having something like are you currently manually doing your Outreach or have you

thought about automating it can also work perfectly so at this stage the fully enriched lead is updated to my air table with funding details personalization variables clean company name and the full LinkedIn analysis which can be used by your sales team to prepare for the sales call the lead is then pushed to instantly ensuring that only highly qualified personalized leads enter the Outreach campaign with funding insights LinkedIn analysis and structured personalization this workflow ensures that every email sent is

targeted relevant and optimized for high response rates now let's take a look inside instantly to see the final result the lead should now have been uploaded to my instantly campaign and if I press on preview we should see this email template being filled in so yes it worked so the first name of the lead was aund then we can see the personalization which is the exact same personalization as was written by the AI and we can see that the variables like company overview ICP of lead paino lead solves are also

filled in so we help rapid integration Solutions SAS teams land meeting with software developers needing Integrations dealing with fast scalable data connections using AI driven Outreach and that's exactly the rest of my template this is what makes the difference between random Cod emails that get ignored and highly targeted Outreach that gets replies instead of just using first name or only comp name like most people do this email now has a personalized first line based on real company insights context on their

funding a message that feels custom written even though it is fully automated this means that every email I sent feels like I sat down and wrote it manually but in reality this entire process runs on autopilot just think about the advantage this gives you instead of spending hours researching leads one by one you now have a system that finds qualifies and personalizes everything without you lifting a finger this is why my response rates are way higher than the typical cold Outreach campaign and why this workflow has

helped me lend multiple clients in a single month but all right that wraps up the full breakdown of my automated lead generation and enrichment system if you want to skip the setup and get this entire workflow instantly you can download it inside my school Community inside you'll get access to this automation and many more my business Sops and direct support from me along with a group of people all scaling their own AI powered Legion agencies so if you're serious about building a system that brings in high quality leads on

autopilot check it out as I said the link is in the description I want to thank you very much for watching and I'll see you in the next one

