a recruitment agency pays me $4,500 per month for an automated sales system that booked them 70 calls last month on autopilot in this video I'll break down exactly how I build it so you can do the same what you're seeing on screen right now is part of that system it is made up of two workflows the first is the lead generation workflow which I'll walk you through step by step and the second is the lead enrichment and Outreach workflow which I'll cover right after together they create a a fully automated

system that not only scrapes and qualifies leads but also enriches them with AI and sends out personalized qu emails at scale before we dive into these workflows I want to quickly mention that I have a school Community where you can download all these exact workflows and other automation Snippets if you are serious about gold outbound this is the fastest way to lend your first client or still your Outreach process inside of the school Community are all the systems that I person ly used to grow my agency to $80,000 per

month and I'm sure you can do the same all right let's get into it starting with the lead generation workflow for this company I knew the best approach was to Target businesses experiencing Active Pain companies that are actively looking to hire Tech Talent these are the companies that already feel the pressure of an unfilled role making them far more likely to respond to the right Outreach to capitalize on that demount I built a workflow that scraped the LinkedIn job Port pulling in companies that are actively hiring for developer

roles this ensures that every lead we contact is relevant High intent and in immediate need of a solution on LinkedIn you can narrow down job post using specific filters to only Target high intent hiring companies instead of reaching out to random businesses we're focusing on companies that already have an open role making them far more likely to respond to our Outreach to ensure the best possible leads I refined the search using four key filters first I only searched for developer roles since this

agency has a strong network of tech Talent next I filtered by experience level only including mid senior positions since those match the skill set of their candidates then I set a minimum salary of $80,000 making sure we're targeting companies that are willing to pay for Quality Talent finally I applied a recency filter ensuring we only see job posts that were listed within the last month because there's no point in reaching out to companies that may have already filled the role after applying these filters

LinkedIn returned us 4,124 results meaning we now have access to a list of over 4,000 companies that are actively hiring for developer roles this is a big enough pool to run an effective called emo campaign and since they're already looking to hire the likelihood of getting responses and booking calls is much higher now the next step is getting all of this data inside of our workflow so first we'll be focusing on this top part the lead generation part now that we have already filtered for job posts we need to

extract all the relevant details and bring them into our system to do this I use an apify scraper inside n8n to pull in company names job titles locations link URLs and other key details directly from LinkedIn setting up the apy scraper is very straightforward but there is one big challenge since we're scraping for 4,000 leads we can't use the Run actor synchronously and get data set items endpoint URL because this process takes longer than 4 minutes which means we can't just sit and wait for the data set

to be ready in real time if he tried to fetch the data immediately after starting the scrape the output would be empty breaking the workflow to solve this we need a workaround that ensures we only proceed once the data set is fully available let me show you how I handle that to solve this I built a flow that weits for the data set to be ready before continuing ensuring we never process incomplete or empty results it works the following first an HTTP note is set up to retrieve the data set containing all the scrip leads however

since we're working with a large volume of data the scrape isn't instant meaning that when the HTTP request is first made the data set is usually or most of the time still empty to handle this I added a code node that checks if the output contains any data if the data set isn't ready yet this node returns a simple response not ready and this acts as a signal for the next step now an if node evaluates the output and if it detects not ready from the previous note it passs to workflow using a weight note

giving the scraper more time to complete once enough time has passed the HTTP request is retriggered to check again if the data set is ready once the data set is no longer empty at this point the if note recognizes that the data is available because the goote didn't output not ready allowing the workflow to continue processing the lead information without any errors setting it up like this ensures that we never attempt to process an incomplete data set preventing errors and making sure every lead is fully scraped before

moving forward however even after successfully scraping the LinkedIn job post the data is never fully complete one of the biggest limitations is that the job posts often don't include key details like the company's website URL or the recruiter's email address and without this information reaching out directly to decision makers becomes much harder to solve this we take an extra step scraping the company's LinkedIn page to pull in missing details first we send an HTTP request to the company's LinkedIn page retrieving the raw HTML

content this gives us access to everything displayed on their page including text that isn't provided in the job post itself next we use a code note to filter out unnecessary elements from the HTML isolating the company's website URL from the extracted HTML since most businesses list their website on their LinkedIn profile this step helps us fill in a critical missing piece of data at this point we've successfully extracted the company's website URL but we still need a reliable way to find Direct email addresses this

is where any email finder comes in with any email finder all we need to do is put the company's domain name and the tool will search the web for verified email addresses associated with that domain instead of giving us random or outdated contacts it provides ranked results meaning the most frequently used and reliable emails appear first this ensures that every email we collect is valid reducing bounce rate and improving deliverability now that we have gathered all the key details the company's name

their website URL and a verified email address it is time to store everything into our CRM I personally use air table but the specific tool doesn't matter what's important is that your CRM can send web hooks because that's what will allow us to seamlessly connect this data to the next workflow the lead enrichment and Outreach process with all the leads now stored and structured properly as you can see the lead generation process is complete but this is just the first half of the system next I'll show you

how we enrich these leads further and automate highly personalized Outreach at skill honestly this was the least interesting part of this system what's coming up next is where things get really powerful now that we have a highly targeted list of leads we can start enriching them with AI and sending personalized gold emails at skill this is the part that turns raw data into booked calls automatically so let's move on to the lead enrichment and Outreach workflow now that we have a segmented list of leads we can move on to what

really matters turning this data into high converting Outreach the next step is lead enrichment where we pull additional company insights to make our emails hyper personalized once we have all the necessary details we move into C email automation where AI fills in the gaps and generates emails that feel 100% human written the goal of this workflow is simple by the time it is done every email variable will will be fully populated and the emails will be automatically uploaded to our email service provider ready to be sent out

automatically before we dive into this workflow let's take a look at the email template I wrote for this specific client and that will be used for our Outreach so the email template I came up with is as follows I always use the same structure it is hi first name I noticed that clean company name has been actively recruiting for job roll for the past job post date so how many weeks and then followed by a little personalization or personalized line which is always a big bonus we've built a fast database of preed developers

enabling companies like samish and atasan to fill critical roles within a week proficient process ensures you meet your prospect deadlines without compromising on Talent quality should I send over some candidates who could be a perfect fit for once again clean company name everything you see that is within brackets will be filled in by AI at the end of this workflow this email is designed to feel tailor made for each recipient putting in key details about their hiring activity to create a message that feels genuine and relevant

once all variables are filled in things like the company name job roll posting date and a unique personalization line this email will sound completely natural no one would ever guess it was generated and sent at skill using AI now now let's go step by step through the workflow that makes this possible before we start enriching the data we need to filter out bad leads so we're not wasting API tokens processing power or time on companies that aren't even a fit for us or for my client in this case for this

client the only qualifier we care about is location the company must be based in the United States that is it everything else like industry or company Size Doesn't Matter for this spe specific Outreach campaign to start this campaign we've set up a simple trigger that starts the enrichment workflow from inside of my air table so here inside my air table all I have to do is check this box which then sends a web hook to n8n using an automation air table which automatically kicks off the workflow so

back in NN the web hook Noe would be the note receiving the web hook sent from Air table and it receives the record ID from the specific lead of which I checked the box and this record ID serves as a unique identifier for the lead allowing us to pull in all the relevant details for the next steps in the process now that the workflow is triggered we can move on to verifying the leads location and scraping additional company details once they qualify so once the web Hook is triggered the record ID is passed to the

next note the air table note which allows us to pull all the relevant lead information from our CRM as you can see on the output side the air table note retrieves everything we've collected so far so like the company's name their website URL LinkedIn profile job details since we've already scraped the job post location we can use this data to filter out companies that aren't based in the US here's how that filter would work the if note is set up to Simply check if the location contains the United States if

it does it is sent on to the true Branch if it doesn't it is sent to the false branch which would delete the lead from our CRM this prevents us from wasting resources and API calls on leads that won't qualify but if the location check confirms that the company is in us the workflow continues and we move forward with scraping additional company data for personalization next up to gather even more useful information we take an extra step scraping the company's LinkedIn page to pull in additional data

that wasn't available in the job post to do this we use a hdp note inside n8n to fetch the raw HTML from the company's LinkedIn page which you can see here on the right side this gives us access to everything that is displayed on the page including details that aren't in the structured job po data once we have the raw HTML we run it through a code node once again this code f filters out all the unnecessary elements removing scripts styling anything that isn't useful for us and this step isolates the

important text ensuring we extract only the key business information that will help us personalize Outreach now that we have the cleaned data we're ready to analyze and enrich it using AI meaning Now we move into the most important part of the workflow which is using AI to extract and enrich data for personalization this is where we take the Raw gra data I just showed you and turn it into actionable insights that make our Outreach feel genuinely customized for each company the first step is summarizing the company data and

for this we use a cat GPT note that processes the cleaned lead in data and generates a structured company summary this summary includes the company size which gives us an idea of their skill and potential hiring needs it also identifies their most recent funding round which is a strong signal that they are in a growth phase and more likely to be hiring the AI then extracts notable Partnerships helping us understand the companies they collaborate with and allowing us to reference them in Outreach if relevant finally it analyzes

recent LinkedIn posts to capture key topics or industry Trends they are focusing on for this specific email we aren't using LinkedIn post insights but we could incorporating them would add another layer of personalization making the out reach even more compelling now that we have a structured summary of the company we move on to the next AI step extracting the key variables needed to personalize and fill in the email template the second large language model note now takes the structured company

summary from the previous one and extract only the specific variables needed for our email template instead of keeping all the extra details from the first AI step this one focuses purely on the data points that will be inserted into the email making sure everything is formed correctly for automation the reason we use two separate AI nodes instead of one comes down to efficiency and functionality while the first AI node generates a full company profile which isn't just useful for outreach it can also be used for sales prep giving a

deeper understanding of the company before hopping on a call the second AI note on the other hand is designed specifically for automation it extracts only the email specific variables and outputs them in a structured Json format as you can see which makes it much easier to integrate with the rest of the workflow coming after this by splitting these steps we ensure that our workflow remains organized scalable and optimized for both Outreach and future sales conversations now that we have the email

ready data we move on to refining the company name to ensure our message sounds completely natur natural and that is the job of the third AI not it is responsible for cleaning up company names before they are inserted into the email this might seem like a very small detail but it makes a huge difference in how natural the Outreach feels many company LinkedIn Pages include suffixes like LLC or Inc and if we were to use those directly in our email it would make the message sound robotic and unnatural because no one says hey I saw

that ecme solution solons LLC is hiring instead we naturally refer to the company as just Acme solutions to fix this as I said we use this AI note and this specific prompt which detects and removes suffixes ensuring the company name appears clean and natural in the final email this makes the Outreach feel human written even though the entire process is automated now that all the personalization variables are ready we move into the final AI step which is structuring the email instead of cat GPT I use cloud AI for this last step

because it's better at formatting structured data into full coherent sentences the AI takes all the extracted details like the company name job rooll job posting date and any custom personalization which just scrapes and extracted and automatically fills in the email template I drag the email template over from the beginning of this workflow to here so you guys can compare the two immediately as you remember from the email template a lot of stuff like their first name cleaned company name job rooll personalization and once again

clean company name was all in Brackets meaning it was yet to be filled in by the AI and what you see in green is the output from the final LM note which was written by CLA I'll read it for you guys so hi alesandro so first name was filled in I noticed that skill stack which was the clean company name has been actively recruiting developers which was the job roll for the past 3 weeks job post day especially following your recent funding round congratulations on this exciting Milestone so this is the personalization

and if I go back to the German the variables we can see that they recently had a funding round so that must have been inside of the HTML from the company LinkedIn page we've built a fast database while this is all pre-written and hasn't been changed and then finally at the end skill stack was once again filled in instead of clean company name this email is now completely customized to the recipient the company name job roll job posting date have all been inserted seamlessly there's even a personalization line referencing the

company's recent funding round making the message feel like it was written specifically for this lead and the best thing is that all of this was done automatically using two key data sources first we pulled the structured information directly from R CRM which included details from the original job B scrape such as the company name and job Ru then we used AI generated insights from the company's LinkedIn page to add deeper personalization like the recent funding or growth Milestones if they would have had those as well at this

point the email feels a 100% human written with no obvious signs that it was generated at skill now that it's fully prepared The Next Step as I already mentioned is uploading everything to our CRM and sending it out through our email automation system we update our CRM by making use of this air table note which we use to upload all of our enrich data to store it for future reference this keeps everything organized making it easy to track which leads have been processed and enriched and also makes it very easy for the

client in this case to prepare for a sales call if the lead would actually book a meeting at some point and at the same time the final email is uploaded to instantly our email service provider for those who aren't familiar with instantly instantly takes care of sending this email automatically to the lead ensuring a fully hands-off Outreach process from lead generation to AI powered personalization and automated sending this workflow is now running at skill or could be running at skill and that is

pretty much it with just two button clicks we've built a fully automated system that transforms raw data into highly personalized Outreach at scale we now have a highly relevant fully enriched lead list filled with companies that are actively hiring and a high probability of responding the emails are AI written but feel 100% human customized for each company using real time scraped data and AI generated insights and most importantly this is a completely hands-off Outreach system working at a level speed and precision

that no manual team could ever match this is the future of outbound sales if you want to access these workflows Snippets and full automation builds like this you can download them inside my school Community whether you're looking to L your first client or fill your agency to six or seven figures this is the fastest way to do it and if you got any value from this breakdown do me a favor hit like subscribe and turn on notifications so you don't miss any upcoming videos I'll be sharing more deep Dives complete with step-by-step

automation breakdowns that you can Implement immediately let me know in the comments what you'd like to see next and I'll catch you in the next one see you soon

